{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c7e4ff1-d55b-42ff-9ad0-78cc0a51e100",
   "metadata": {},
   "source": [
    "# Microwave acid digestion run analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24aecef-fd13-4699-a3ba-95c739685567",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# options: inline or widget\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbda27c7-3c08-4456-8388-b79e18640ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MADProfile(object):\n",
    "    def __init__(self, filename, sample_info=None):\n",
    "        self.read_multiwave_csv(filename)\n",
    "        self.process_multiwave_metadata()\n",
    "        self.sample_info = sample_info\n",
    "\n",
    "    def read_multiwave_csv(self, filename):\n",
    "        from datetime import datetime, timedelta\n",
    "        with open(filename, encoding = \"utf-16le\") as multiwave_file:\n",
    "            self.metadata = []\n",
    "            for line in multiwave_file:\n",
    "                self.metadata.append(line)\n",
    "                if line.startswith('Result Data'):\n",
    "                    break\n",
    "            self.data = pd.read_csv(multiwave_file, sep='\\t')\n",
    "            self.data[\"Time\"] = self.data[\"Time\"].apply(\n",
    "                lambda x: datetime.strptime(x, '%H:%M:%S')#.time()\n",
    "            ).apply(lambda t: timedelta(hours=t.hour, minutes=t.minute, seconds=t.second).total_seconds())\n",
    "        return self.data\n",
    "\n",
    "    def process_multiwave_metadata(self):\n",
    "        self.metadata = [tuple(l.strip().split('\\t')) for l in self.metadata]\n",
    "        try:\n",
    "            self.warnings = self.metadata[self.metadata.index(('Warnings',))+1:-2]\n",
    "            self.metadata = self.metadata[:self.metadata.index(('Warnings',))-1]\n",
    "        except ValueError:\n",
    "            self.warnings = None\n",
    "            self.metadata = self.metadata[:-3]\n",
    "        self.metadata = pd.Series({l[0]:l[1] if len(l)==2 else l[1:] for l in self.metadata if l[0]})\n",
    "        self.vessels = int(self.metadata['Number of Vessels'])\n",
    "        if self.vessels == 1:\n",
    "            self.vessel_indices = (1,)\n",
    "            self.plot_config = {'nrows':1, 'ncols':1}\n",
    "        elif self.vessels == 3:\n",
    "            self.vessel_indices = (3,7,11)\n",
    "            self.plot_config = {'nrows':1, 'ncols':3}\n",
    "        elif self.vessels == 4:\n",
    "            self.vessel_indices = (1,4,7,10)\n",
    "            self.plot_config = {'nrows':2, 'ncols':2}\n",
    "        elif self.vessels == 6:\n",
    "            self.vessel_indices = (1,3,5,7,9,11)\n",
    "            self.plot_config = {'nrows':2, 'ncols':3}\n",
    "        elif self.vessels == 8:\n",
    "            self.vessel_indices = (2,3,5,6,8,9,11,12)\n",
    "            self.plot_config = {'nrows':4, 'ncols':2}\n",
    "        elif self.vessels == 12:\n",
    "            self.vessel_indices = range(1,13)\n",
    "            self.plot_config = {'nrows':4, 'ncols':3}\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "        \n",
    "    def plot(self):\n",
    "        return self.data[[\n",
    "            \"Time\"]+[f\"T Pos. {i}\" for i in self.vessel_indices]+[\"Power\"\n",
    "        ]].ffill().set_index(\"Time\").plot.line()\n",
    "\n",
    "    def identify_profile_features(self, sample, window_length=11, plateau_threshold=0.1, plateau_size=10, inflection_threshold = 0.02, peak_height=10, ax=None, legend=True):\n",
    "        from scipy.signal import savgol_filter, find_peaks\n",
    "        import numpy as np\n",
    "        sample_data = pd.DataFrame({'raw':self.data.set_index('Time')[sample].dropna()})\n",
    "        sample_data = sample_data.reset_index().drop_duplicates(['Time']).set_index('Time')\n",
    "        sample_data['smooth'] = savgol_filter(sample_data['raw'], window_length=window_length, polyorder=2)\n",
    "        with np.errstate(divide='ignore'):\n",
    "            sample_data['diff'] = np.gradient(sample_data[\"smooth\"], sample_data.index)\n",
    "            sample_data['diff2nd'] = np.gradient(sample_data[\"diff\"], sample_data.index)\n",
    "        ax = sample_data.plot.line(ax=ax)\n",
    "        # Identify key points (e.g., peaks or plateaus)\n",
    "        key_points = np.where(np.abs(sample_data['diff']) < plateau_threshold)[0]  # Example threshold, start with 0.1\n",
    "        sample_data['key_point'] = False\n",
    "        sample_data.loc[sample_data.index[key_points], 'key_point'] = True\n",
    "        ax.vlines(sample_data.index[key_points], ymin=0, ymax=5, linestyle='--', alpha=0.5)\n",
    "        # Calculate plateau ranges\n",
    "        plateaus = sample_data[sample_data.key_point == True].groupby(\n",
    "            (sample_data.key_point != True).cumsum()\n",
    "        ).apply(\n",
    "            lambda x: pd.Series({\n",
    "                'plateau_start':x.index.min(),\n",
    "                'plateau_midpoint':x.index[len(x)//2],\n",
    "                'plateau_end':x.index.max()\n",
    "            })\n",
    "        ).query(\n",
    "            # Only select plateaus of a minimum size\n",
    "            f\"plateau_end - plateau_start >= {plateau_size}\"\n",
    "        ).reset_index(drop=True)\n",
    "        sample_data = sample_data.join(\n",
    "            plateaus.set_index('plateau_midpoint')\n",
    "        )\n",
    "        plateaus = sample_data[['smooth','plateau_start','plateau_end']].dropna().reset_index()\n",
    "        ax.hlines(\n",
    "            plateaus.smooth, xmin=plateaus.plateau_start, xmax=plateaus.plateau_end,\n",
    "            linewidth=3, label='Plateaus', color='black', alpha=0.7, zorder=5\n",
    "        )\n",
    "        # Peaks\n",
    "        peaks, peak_heights = find_peaks(sample_data.smooth, height=peak_height)\n",
    "        sample_data['peak'] = False\n",
    "        sample_data.loc[sample_data.index[peaks], 'peak'] = True\n",
    "        ax.scatter(\n",
    "            sample_data.index[peaks], sample_data.iloc[peaks]['smooth'],\n",
    "            label='Peaks', color='green', alpha=0.7, zorder=5\n",
    "        )\n",
    "        # Detect inflection points (where second derivative changes sign)\n",
    "        inflection_points = np.where(\n",
    "            (np.diff(np.sign(sample_data['diff2nd'])) != 0) & \n",
    "            (np.abs(sample_data['diff2nd']) > inflection_threshold).iloc[:-1]\n",
    "        )[0]\n",
    "        #inflection_points = np.where(np.diff(np.sign(sample_data['diff2nd'])))[0]\n",
    "        sample_data['inflection_point'] = False\n",
    "        sample_data.loc[sample_data.index[inflection_points], 'inflection_point'] = True\n",
    "        ax.scatter(\n",
    "            sample_data.index[inflection_points], sample_data.iloc[inflection_points]['smooth'],\n",
    "            label='Inflection points', color='purple', alpha=0.7, zorder=5\n",
    "        )\n",
    "        if not legend: ax.get_legend().remove()\n",
    "            \n",
    "        return sample_data, ax\n",
    "\n",
    "    def profile_feature_analysis(self, window_length=11, plateau_threshold=0.1, plateau_size=10, inflection_threshold = 0.02, peak_height=10):\n",
    "        samples = [f\"T Pos. {i}\" for i in self.vessel_indices]\n",
    "        self.features = {}\n",
    "        fig, axes = plt.subplots(\n",
    "            nrows=self.plot_config['nrows'], ncols=self.plot_config['ncols'], sharex=True\n",
    "        )\n",
    "        for s, ax in zip(samples,axes.flatten()):\n",
    "            ax.set_title(s)\n",
    "            sd, _ = self.identify_profile_features(\n",
    "                s, window_length=window_length, \n",
    "                plateau_threshold=plateau_threshold, \n",
    "                inflection_threshold = inflection_threshold,\n",
    "                peak_height=peak_height, ax=ax, legend=False\n",
    "            )\n",
    "            self.features[s] = {\n",
    "                'key_points':sd.key_point.sum(),\n",
    "                'plateaus':len(sd.plateau_start.dropna()),\n",
    "                'peaks':sd.peak.sum(),\n",
    "                'inflections':sd.inflection_point.sum()\n",
    "            }\n",
    "        self.features = pd.DataFrame(self.features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd1ba83-8044-4f01-817a-4755a51df424",
   "metadata": {},
   "outputs": [],
   "source": [
    "#! file -bi user/85000797 DSK0761_2.csv\n",
    "mad_results = MADProfile('data/85000797_DSK0761_2.csv')\n",
    "mad_results.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0324d08-fad6-42be-b267-c732b888b48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment with interpolation\n",
    "mad_results.data[[\"Time\",\"T Pos. 1\",\"T Pos. 4\",\"T Pos. 7\",\"T Pos. 10\",\"Power\"]].set_index(\"Time\").infer_objects(copy=False).interpolate().plot.line()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845564f7-0c99-495b-8b6f-f0cf848a8533",
   "metadata": {},
   "outputs": [],
   "source": [
    "mad_results = MADProfile('data/500mg organic b ramp to 100.csv')\n",
    "mad_results.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d101f0-7ce4-4e24-88ce-56872a0a4bd4",
   "metadata": {},
   "source": [
    "## Analyze profile\n",
    "### Profile for 1 sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29344447-9c9e-44e5-9258-0998e93b0806",
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_settings = {\n",
    "    'window_length': 20,\n",
    "    'plateau_threshold': 0.05,\n",
    "    'plateau_size': 60,\n",
    "    'inflection_threshold': 0.05,\n",
    "    'peak_height': 20\n",
    "}\n",
    "sample_data, ax = mad_results.identify_profile_features('T Pos. 1',**signal_settings)\n",
    "print({\n",
    "                'key_points':sample_data.key_point.sum(),\n",
    "                'plateaus':len(sample_data.plateau_start.dropna()),\n",
    "                'peaks':sample_data.peak.sum(),\n",
    "                'inflections':sample_data.inflection_point.sum()\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de3c8b2-54fd-4402-8035-38b8115a2d2b",
   "metadata": {},
   "source": [
    "### Profiles for all samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94c674b-5658-4383-b489-f5bf2349cfbb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mad_results.profile_feature_analysis(**signal_settings)\n",
    "print(mad_results.features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6369dce6-493a-43db-814c-a2e07428e995",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
